≪ソフトウェアバージョン≫
# cat /etc/oracle-release
Oracle Linux Server release 7.6

# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.6 (Maipo)

≪カーネル変更≫
# uname -r
4.14.35-1818.3.3.el7uek.x86_64

# awk -F\' '$1=="menuentry " {print i++ " : " $2}' /etc/grub2.cfg
0 : Oracle Linux Server (4.14.35-1818.3.3.el7uek.x86_64 with Unbreakable Enterprise Kernel) 7.6
1 : Oracle Linux Server (3.10.0-957.el7.x86_64 with Linux) 7.6
2 : Oracle Linux Server (0-rescue-34e2abab932d41e4b6373792b1d48d23 with Linux) 7.6
# grub2-set-default 1
# grub2-editenv list
# shutdown -r now
...
# uname -r
3.10.0-957.el7.x86_64


≪ローカルリポジトリ作成≫
# mount -r /dev/sr1 /media;df -h /media

# FILE=/etc/yum.repos.d/ol7-iso.repo
# echo -e "[ol7-iso] \n\
name=Oracle Linux \$releasever - x86_64 - ISO \n\
baseurl=file:///media/ \n\
enabled=0 \n\
gpgcheck=1 \n\
gpgkey=file:///media/RPM-GPG-KEY-oracle \n"|tee -a $FILE

# echo "alias yum2='yum --disablerepo=* --enablerepo=ol7-iso'" >> $HOME/.bashrc
# source $HOME/.bashrc
# alias|grep yum
# yum2 list

≪パッケージインストール≫
# alias yum2='yum --disablerepo=* --enablerepo=ol7iso'
# export LANG=C
# yum2 install -y xorg-x11-xauth.x86_64 bzip2.x86_64 xorg-x11-xauth.x86_64 chrony.x86_64 gcc-c++.x86_64
# yum2 install -y kernel-devel.x86_64

### VboxAddonsインストール
# mount -r /dev/sr0 /mnt
# /mnt/VBoxLinuxAdditions.run

≪VBox共有フォルダマウント≫
# echo -e "media                   /opt/media              vboxsf  defaults,uid=54321,gid=54321,fmode=0777,dmode=0777       0 0"|tee -a /etc/fstab
# mkdir /opt/media && mount /opt/media && df -h /opt/media

≪パッケージインストール≫
# yum2 localinstall -y /opt/media/oracle-database-preinstall-19c-1.0-1.el7.x86_64.rpm

# yum clean all
# umount /media
# umount /mnt

≪セキュリティ設定≫
# cp /etc/sysconfig/selinux /etc/sysconfig/selinux.bak
# sed -e 's/SELINUX=enforcing/SELINUX=disabled/' /etc/sysconfig/selinux -i
# diff /etc/sysconfig/selinux /etc/sysconfig/selinux.bak

# cp /etc/selinux/config /etc/selinux/config.bak
# sed -e 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config -i
# diff /etc/selinux/config /etc/selinux/config.bak

	以下のように表示されること
	-------------------------------
	7c7
	< SELINUX=disabled
	---
	> SELINUX=enforcing
	-------------------------------

# systemctl disable firewalld.service
# systemctl stop firewalld.service
# systemctl list-unit-files firewalld.service
	以下のように表示されること
	-------------------------------
	UNIT FILE         STATE
	firewalld.service disabled

	1 unit files listed.
	-------------------------------


≪グループ、ユーザ、ディレクトリ作成≫
# groupadd -g 54321 oinstall
# groupadd -g 54322 dba
# groupadd -g 54323 oper
# groupadd -g 54324 backupdba
# groupadd -g 54325 dgdba
# groupadd -g 54326 kmdba
# groupadd -g 54327 asmdba
# groupadd -g 54328 asmadmin
# groupadd -g 54329 asmoper
# groupadd -g 54330 racdba

# grep 543[21-30] /etc/group
oinstall:x:54321:
dba:x:54322:oracle
oper:x:54323:
backupdba:x:54324:
dgdba:x:54325:
kmdba:x:54326:
asmdba:x:54327:
asmadmin:x:54328:
asmoper:x:54329:

# useradd -u 54322 -g oinstall -G asmadmin,asmdba,asmoper grid
# usermod -u 54321 -g oinstall -G dba,oper,asmdba oracle
# echo "oracle" | passwd --stdin grid
# echo "oracle" | passwd --stdin oracle
# id grid
# id oracle

≪ディレクトリ設定≫
# mkdir -p /u01/grid
# mkdir -p /u01/gbase
# mkdir -p /u01/base/app/database
# chown -R grid:oinstall /u01
# chown -R oracle:oinstall /u01/base
# chmod -R 775 /u01

≪カーネルパラメータ設定≫
# FILE=/etc/sysctl.conf
# echo -e "vm.nr_hugepages = 2048 \n\
net.ipv4.conf.enp0s9.rp_filter = 2\n\
net.ipv4.conf.enp0s8.rp_filter = 2\n\
net.ipv4.conf.enp0s3.rp_filter = 1"|tee -a /etc/sysctl.conf

# sysctl -p

≪リソース制限設定≫
# FILE=/etc/security/limits.conf
# echo -e "@oinstall    soft    nproc    2047 \n\
@oinstall    hard    nproc   16384 \n\
@oinstall    soft    nofile   1024 \n\
@oinstall    hard    nofile  65536 \n\
@oinstall    soft    stack   10240 \n\
@oinstall    hard    stack   10240 \n\
@oinstall    soft    memlock 7549747 \n\
@oinstall    hard    memlock 7549747 \n"|tee -a $FILE
# tail -6 $FILE
	以下のように表示されること
	-------------------------------
	@oinstall    soft    nproc    2047
	@oinstall    hard    nproc   16384
	@oinstall    soft    nofile   1024
	@oinstall    hard    nofile  65536
	@oinstall    soft    stack   10240
	@oinstall    hard    stack   10240
	@oinstall    soft    memlock 7549747
	@oinstall    hard    memlock 7549747
	-------------------------------

≪PAM認証設定≫
# echo "session required pam_limits.so"|tee -a /etc/pam.d/login
# tail -1 /etc/pam.d/login
	以下のように表示されること
	-------------------------------
	session required pam_limits.so
	-------------------------------

≪リソース制限設定②≫
# FILE=/etc/profile
# echo -e 'if [ $USER = "oracle" ]; then
    if [ $SHELL = "/bin/ksh" ]; then
       ulimit -u 16384
       ulimit -n 65536
    else
       ulimit -u 16384 -n 65536
    fi
fi'|tee -a $FILE
# tail -8 /etc/profile
	以下のように表示されること
	-------------------------------
	if [ $USER = "oracle" ]; then
	    if [ $SHELL = "/bin/ksh" ]; then
	       ulimit -u 16384
	       ulimit -n 65536
	    else
	       ulimit -u 16384 -n 65536
	    fi
	fi
	-------------------------------


≪NTP設定≫
# cp /etc/chrony.conf /etc/chrony.conf.bak
# sed -e 's/^server/#server/g' /etc/chrony.conf -i
# echo -e "server 192.168.56.254 iburst" |tee -a /etc/chrony.conf
# systemctl restart chronyd.service
# systemctl status chronyd.service
# chronyc sources
# diff /etc/chrony.conf /etc/chrony.conf.bak

# systemctl stop avahi-daemon.socket
# systemctl stop avahi-daemon.service
# systemctl disable avahi-daemon.socket
# systemctl disable avahi-daemon.service


≪クローン node1 -> node2≫
node2起動

≪ホスト名変更≫
# hostnamectl set-hostname node2

＜IPアドレス変更＞
# nmcli c modify enp0s3 ipv4.addresses 192.168.56.52/24;nmcli c down enp0s3;nmcli c up enp0s3
# nmcli c modify enp0s8 ipv4.addresses 192.168.100.52/24;nmcli c down enp0s8;nmcli c up enp0s8
# nmcli c modify enp0s9 ipv4.addresses 192.168.200.52/24;nmcli c down enp0s9;nmcli c up enp0s9

# shutdown -h now

≪クローン node1 -> node3≫
node2起動

≪ホスト名変更≫
# hostnamectl set-hostname node3

＜IPアドレス変更＞
# nmcli c modify enp0s3 ipv4.addresses 192.168.56.53/24;nmcli c down enp0s3;nmcli c up enp0s3
# nmcli c modify enp0s8 ipv4.addresses 192.168.100.53/24;nmcli c down enp0s8;nmcli c up enp0s8
# nmcli c modify enp0s9 ipv4.addresses 192.168.200.53/24;nmcli c down enp0s9;nmcli c up enp0s9

# shutdown -h now

≪共有ディスク作成≫
mkdir /vbox_ssd/shared-disk-rac-193;cd /vbox_ssd/shared-disk-rac-193
vboxmanage createmedium disk --filename rac-193-asm-disk1.vdi --size 1024 --format VDI --variant Fixed # GRID
vboxmanage createmedium disk --filename rac-193-asm-disk2.vdi --size 1024 --format VDI --variant Fixed # GRID
vboxmanage createmedium disk --filename rac-193-asm-disk3.vdi --size 1024 --format VDI --variant Fixed # GRID
vboxmanage createmedium disk --filename rac-193-asm-disk4.vdi --size 10240 --format VDI --variant Fixed # DATA
vboxmanage createmedium disk --filename rac-193-asm-disk5.vdi --size 1024 --format VDI --variant Fixed # RECO
vboxmanage createmedium disk --filename rac-193-asm-disk6.vdi --size 30720 --format VDI --variant Fixed # GIMR

vboxmanage modifymedium disk rac-193-asm-disk1.vdi --type shareable
vboxmanage modifymedium disk rac-193-asm-disk2.vdi --type shareable
vboxmanage modifymedium disk rac-193-asm-disk3.vdi --type shareable
vboxmanage modifymedium disk rac-193-asm-disk4.vdi --type shareable
vboxmanage modifymedium disk rac-193-asm-disk5.vdi --type shareable
vboxmanage modifymedium disk rac-193-asm-disk6.vdi --type shareable

vboxmanage storageattach node1-rac-193 --storagectl "SATA" --port 1 --device 0 --type hdd --medium rac-193-asm-disk1.vdi
vboxmanage storageattach node2-rac-193 --storagectl "SATA" --port 1 --device 0 --type hdd --medium rac-193-asm-disk1.vdi
vboxmanage storageattach node3-rac-193 --storagectl "SATA" --port 1 --device 0 --type hdd --medium rac-193-asm-disk1.vdi

vboxmanage storageattach node1-rac-193 --storagectl "SATA" --port 2 --device 0 --type hdd --medium rac-193-asm-disk2.vdi
vboxmanage storageattach node2-rac-193 --storagectl "SATA" --port 2 --device 0 --type hdd --medium rac-193-asm-disk2.vdi
vboxmanage storageattach node3-rac-193 --storagectl "SATA" --port 2 --device 0 --type hdd --medium rac-193-asm-disk2.vdi

vboxmanage storageattach node1-rac-193 --storagectl "SATA" --port 3 --device 0 --type hdd --medium rac-193-asm-disk3.vdi
vboxmanage storageattach node2-rac-193 --storagectl "SATA" --port 3 --device 0 --type hdd --medium rac-193-asm-disk3.vdi
vboxmanage storageattach node3-rac-193 --storagectl "SATA" --port 3 --device 0 --type hdd --medium rac-193-asm-disk3.vdi

vboxmanage storageattach node1-rac-193 --storagectl "SATA" --port 4 --device 0 --type hdd --medium rac-193-asm-disk4.vdi
vboxmanage storageattach node2-rac-193 --storagectl "SATA" --port 4 --device 0 --type hdd --medium rac-193-asm-disk4.vdi
vboxmanage storageattach node3-rac-193 --storagectl "SATA" --port 4 --device 0 --type hdd --medium rac-193-asm-disk4.vdi

vboxmanage storageattach node1-rac-193 --storagectl "SATA" --port 5 --device 0 --type hdd --medium rac-193-asm-disk5.vdi
vboxmanage storageattach node2-rac-193 --storagectl "SATA" --port 5 --device 0 --type hdd --medium rac-193-asm-disk5.vdi
vboxmanage storageattach node3-rac-193 --storagectl "SATA" --port 5 --device 0 --type hdd --medium rac-193-asm-disk5.vdi

vboxmanage storageattach node1-rac-193 --storagectl "SATA" --port 6 --device 0 --type hdd --medium rac-193-asm-disk6.vdi
vboxmanage storageattach node2-rac-193 --storagectl "SATA" --port 6 --device 0 --type hdd --medium rac-193-asm-disk6.vdi
vboxmanage storageattach node3-rac-193 --storagectl "SATA" --port 6 --device 0 --type hdd --medium rac-193-asm-disk6.vdi

≪ストレージディスク設定≫
※ノード1のみ
parted /dev/sdb～/dev/sdg

partprobe


≪ユーザ等価性設定≫ (grid、oracleユーザで実施)
- 両ノードで実施
$ mkdir $HOME/.ssh
$ ssh-keygen -t rsa -C "common@oracle.com"
$ mv .ssh/id_rsa.pub .ssh/authorized_keys
$ scp -r .ssh node2:
$ ssh node1 date;ssh node2 date


≪Gridメディア解凍≫
unzip -q /opt/media/LINUX.X64_193000_grid_home.zip -d /u01/grid/

≪ASMディスク作成≫
# export ORACLE_HOME=/u01/grid
# export ORACLE_BASE=/tmp
# $ORACLE_HOME/bin/asmcmd afd_label GRID_ASMDISK1 /dev/sdb1 --init
# $ORACLE_HOME/bin/asmcmd afd_label GRID_ASMDISK2 /dev/sdc1 --init
# $ORACLE_HOME/bin/asmcmd afd_label GRID_ASMDISK3 /dev/sdd1 --init
# $ORACLE_HOME/bin/asmcmd afd_label DATA_ASMDISK1 /dev/sde1 --init
# $ORACLE_HOME/bin/asmcmd afd_label RECO_ASMDISK1 /dev/sdf1 --init
# $ORACLE_HOME/bin/asmcmd afd_label MGMT_ASMDISK1 /dev/sdg1 --init

# $ORACLE_HOME/bin/asmcmd afd_lslbl '/dev/sd*'
--------------------------------------------------------------------------------
Label                     Duplicate  Path
================================================================================
GRID_ASMDISK1                         /dev/sdc1
GRID_ASMDISK2                         /dev/sdg1
GRID_ASMDISK3                         /dev/sdb1
DATA_ASMDISK1                         /dev/sdd1
RECO_ASMDISK1                         /dev/sde1
MGMT_ASMDISK1                         /dev/sdf1

≪ASMディスクラベルを削除≫
※必要な場合のみ
# $ORACLE_HOME/bin/asmcmd afd_unlabel '/dev/sdb1' -f --init
# $ORACLE_HOME/bin/asmcmd afd_unlabel '/dev/sdc1' -f --init
# $ORACLE_HOME/bin/asmcmd afd_unlabel '/dev/sdd1' -f --init
# $ORACLE_HOME/bin/asmcmd afd_unlabel '/dev/sde1' -f --init
# $ORACLE_HOME/bin/asmcmd afd_unlabel '/dev/sdf1' -f --init
# $ORACLE_HOME/bin/asmcmd afd_unlabel '/dev/sdg1' -f --init
# dd if=/dev/zero of=/dev/sdb1 bs=1M count=5
# dd if=/dev/zero of=/dev/sdc1 bs=1M count=5
# dd if=/dev/zero of=/dev/sdd1 bs=1M count=5
# dd if=/dev/zero of=/dev/sde1 bs=1M count=5
# dd if=/dev/zero of=/dev/sdf1 bs=1M count=5
# dd if=/dev/zero of=/dev/sdg1 bs=1M count=5

# unset ORACLE_BASE

≪cvuqdiskインストール≫
# rpm -ivh /opt/media/cvuqdisk-1.0.10-1.rpm

≪GIインストール≫
# xauth list
node1/unix:10  MIT-MAGIC-COOKIE-1  bbcc7cc36b9d14898396d4c359efa07d
# env|grep DISPLAY
DISPLAY=localhost:10.0
# xhost +
# su - grid
$ xauth add unix:10  MIT-MAGIC-COOKIE-1  bbcc7cc36b9d14898396d4c35
9efa07d
$ export DISPLAY=localhost:10.0
$ $GI_HOME/gridSetup.sh 

個別パッチを同時に適用
$ $GI_HOME/gridSetup.sh -applyOneOffs 

RUを同時に適用
$ $GI_HOME/gridSetup.sh -applyPSU 

# echo -e "export ORACLE_BASE=/u01/app/grid \n\
export ORACLE_HOME=$GI_HOME \n\
export PATH=\$ORACLE_HOME/bin:\$ORACLE_HOME/OPatch:\$PATH \n"|tee -a /home/grid/.bash_profile

# echo -e "export PATH=$GI_HOME/bin:$GI_HOME/OPatch:\$PATH \n"|tee -a /root/.bash_profile

≪DBメディア解凍≫
DB_HOME=/u01/app/oracle/product/18.0.0/dbhome_1
# mkdir -p $DB_HOME
# chown -R oracle:oinstall /u01/app/oracle
# chmod -R 775 /u01/app/oracle
# su -l oracle -c "unzip -q /opt/media/LINUX.X64_180000_db_home.zip -d $DB_HOME"

≪DBインストール≫
$DB_HOME/runInstaller


# echo -e "export ORACLE_BASE=/u01/app/oracle \n\
export ORACLE_HOME=$DB_HOME \n\
export PATH=\$ORACLE_HOME/bin:\$ORACLE_HOME/OPatch:\$PATH \n"|tee -a /home/oracle/.bash_profile
